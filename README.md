# ğŸ§ ğŸ™ï¸ PILL â€“ Pi LLaMA Voice-to-Voice AI Assistant

**PILL** (Pi LLaMA) is an offline, privacy-first, real-time voice assistant powered by Whisper (STT), TinyLLaMA (LLM), and Piper (TTS), built specifically for the Raspberry Pi 4. It was created as a Bachelor's Major Project to demonstrate an end-to-end voice interaction system on constrained hardware.

---

## ğŸ”§ Key Features

- ğŸ¤ Real-time voice input and output
- ğŸ§  LLM-powered response with TinyLLaMA (via llama.cpp)
- ğŸ—£ï¸ Natural-sounding speech via Piper TTS
- ğŸ§ Fully local and open-source
- ğŸ“ Optimized for Raspberry Pi 4

---

## ğŸ—‚ï¸ Project Structure

```bash
pill/
â”œâ”€â”€ audio/                          # Temporary audio files
â”‚   â””â”€â”€ speech.wav
â”œâ”€â”€ bin/                            # Executable scripts
â”‚   â”œâ”€â”€ run.sh                      # Main voice-to-voice pipeline
â”‚   â”œâ”€â”€ speak                       # TTS wrapper
â”‚   â””â”€â”€ tokens                      # LLaMA wrapper
â”œâ”€â”€ stt/
â”‚   â”œâ”€â”€ bin/                        # Whisper binary
â”‚   â””â”€â”€ models/                     # Whisper model (e.g. ggml-tiny.bin)
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ bin/                        # llama.cpp binary and shared libs
â”‚   â””â”€â”€ models/                     # GGUF LLaMA models
â”œâ”€â”€ tts/
â”‚   â”œâ”€â”€ piper/                      # Piper binary
â”‚   â””â”€â”€ voice/                      # ONNX voice models
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ” Workflow Overview

### ğŸ—£ï¸ 1. User Speaks
Microphone input is captured via PyAudio.

### ğŸ§ 2. Speech-to-Text (STT)
Audio stream is transcribed in real-time using [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) running a base or tiny model.

**Result:** `"Whatâ€™s the weather today?"`

### ğŸ§  3. Text Generation with LLaMA
Transcribed text is sent to [TinyLLaMA](https://huggingface.co/TinyLlama) running via [llama.cpp](https://github.com/ggerganov/llama.cpp) with a lightweight quantized model (e.g., 3B Q4_K_M).

Context is preserved to maintain conversation state.

**Result:** `"I'm not connected to the internet, but it's always sunny with me!"`

### ğŸ—£ï¸ 4. Text-to-Speech (TTS)
Generated response is passed to [Piper TTS](https://github.com/rhasspy/piper) using a selected voice model.

Audio is streamed back to the speaker in real time.

## ğŸ›  Dependencies

* [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) â€“ Real-time STT
* [LLaMA.cpp](https://github.com/ggerganov/llama.cpp) â€“ TinyLLaMA inference
* [Piper TTS](https://github.com/rhasspy/piper) â€“ Lightweight TTS engine

# setup.sh
mkdir -p stt/models llm/models tts/voice/libritts_r
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin -P stt/models/
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US-libritts_r-medium.onnx -P tts/voice/libritts_r/


### Build Whisper, LLaMA, Piper
Follow official repo instructions or use your own builds and place the binaries in:
## ğŸ§  Models & Binaries

### 1. Whisper (STT)
* **ğŸ”§ Binary:** `whisper-cli` (from [whisper.cpp](https://github.com/ggerganov/whisper.cpp))
    ```
    ğŸ“ Path: stt/bin/whisper-cli
    ```
* **ğŸ“„ Model File:** `ggml-tiny.bin`
    ```
    ğŸ“ Path: stt/models/ggml-tiny.bin
    ```
    ```bash
    # Download model
    wget [https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin](https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin) -P stt/models/
    ```

### 2. TinyLLaMA (LLM)
* **ğŸ”§ Binary:** `llama-cli` (from [llama.cpp](https://github.com/ggerganov/llama.cpp))
    ```
    ğŸ“ Path: llm/bin/llama-cli
    ```
* **ğŸ“„ Model File:** `tinyllama_1b_q4_chat.gguf`
    ```
    ğŸ“ Path: llm/models/tinyllama_1b_q4_chat.gguf
    ```
    ```bash
    # Example download source (you may need to convert to GGUF format):
    wget [https://huggingface.co/cognitivecomputations/TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/cognitivecomputations/TinyLlama-1.1B-Chat-v1.0) -O /tmp/tinyllama.pth
    # (Conversion to GGUF not shown here - refer to llama.cpp documentation)
    # Move the converted GGUF file to llm/models/tinyllama_1b_q4_chat.gguf
    ```
    Make sure your version is quantized (e.g., Q4 or Q5) for Raspberry Pi compatibility.

### 3. Piper (TTS)
* **ğŸ”§ Binary:** `piper` (from [piper](https://github.com/rhasspy/piper))
    ```
    ğŸ“ Path: tts/piper/piper
    ```
* **ğŸ“„ Voice Model:** `en_US-libritts_r-medium.onnx`
    ```
    ğŸ“ Path: tts/voice/libritts_r/en_US-libritts_r-medium.onnx
    ```
    ```bash
    # Download from official model list:
    # [https://huggingface.co/rhasspy/piper-voices](https://huggingface.co/rhasspy/piper-voices)

    # Example:
    wget [https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US-libritts_r-medium.onnx](https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US-libritts_r-medium.onnx) -P tts/voice/libritts_r/
    ```

## âœ… Additional Notes

### Audio Format Requirements:

* WAV
* Mono
* 16-bit
* 16000 Hz sample rate

### Environment Variables:

Set `LD_LIBRARY_PATH` to include `llm/bin` for `llama.cpp` dynamic libraries:

```bash
export LD_LIBRARY_PATH=llm/bin:$LD_LIBRARY_PATH
Hardware Tested:
Raspberry Pi 4 (4GB/8GB)
USB mic or onboard mic (via arecord)
ğŸ“ Directory Summary
Bash

stt/
â”œâ”€â”€ bin/whisper-cli
â””â”€â”€ models/ggml-tiny.bin

llm/
â”œâ”€â”€ bin/llama-cli
â””â”€â”€ models/tinyllama_1b_q4_chat.gguf

tts/
â”œâ”€â”€ piper/piper
â””â”€â”€ voice/libritts_r/en_US-libritts_r-medium.onnx
ğŸ§ª Verification
After setup, you can test each module separately:

Whisper:
Bash

./stt/bin/whisper-cli ../audio/speech.wav --model ../stt/models/ggml-tiny.bin
LLaMA:
Bash

./llm/bin/llama-cli -m ../llm/models/tinyllama_1b_q4_chat.gguf -p "Hello, who are you?" -n 50
Piper:
Bash

./tts/piper/piper --model ../tts/voice/libritts_r/en_US-libritts_r-medium.onnx --text "Hello, world." --output_file output.wav
# Play the output audio file (e.g., using aplay on Linux):
# aplay output.wav
